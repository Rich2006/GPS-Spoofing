{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of All 1DCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm0pDqNjTTjd"
      },
      "source": [
        "from six.moves import cPickle as pickle\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqIpK8_4ZJNU",
        "outputId": "090492f2-d358-4da4-a88e-aa006f048f28"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaNshQzMcI8J"
      },
      "source": [
        "data_dir = '/content/drive/My Drive/Colab Notebooks/HEX New folder'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzEaINfQbnUa",
        "outputId": "bfc339c3-f391-4186-9915-7c838bbd6391"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "#from keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import pandas.util.testing as tm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxJ3Nwnvzqsq"
      },
      "source": [
        "def ReshapeY(Y_train,n):\n",
        "    Y = list()\n",
        "    for x in Y_train:\n",
        "        Y.append(find_1(x, n))\n",
        "\n",
        "    Y = np.array(Y)\n",
        "    return Y\n",
        "    print(Y.shape)\n",
        "    \n",
        "    \n",
        "# look for 1 ( spoof) in each   \n",
        "def find_1(x, n):\n",
        "    if 1 in x:\n",
        "        res = 1\n",
        "    else: \n",
        "        res = 0\n",
        "    return res    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "def LOAD_data(path ):\n",
        "    filenames = glob.glob(path + \"/*.csv\")\n",
        "\n",
        "    dfs = []\n",
        "    for filename in filenames:\n",
        "        df=pd.read_csv(filename)\n",
        "        if 'le0.csv'== filename[-7:]:\n",
        "            df['attack'] = 0\n",
        "            df = df[190:]\n",
        "\n",
        "        else:\n",
        "            df['attack'] = 1\n",
        "        dfa = df['attack']\n",
        "        df = df[14:]\n",
        "        df = df.iloc[:-180]\n",
        "        df = df.select_dtypes(exclude=['object','bool'])         #remove nan\n",
        "        df = df.loc[:, (df != 0).any(axis=0)]                    #remove zeros\n",
        "        df = df.drop(df.std()[(df.std() == 0)].index, axis=1)   #remove equals\n",
        "        df=((df-df.min())/(df.max()-df.min()))*1\n",
        "\n",
        "        df['attack'] = dfa\n",
        "        dfs.append(df)\n",
        "\n",
        "\n",
        "    # Concatenate all data into one DataFrame\n",
        "    df = pd.concat(dfs, ignore_index=True)\n",
        "        #df.head()\n",
        "        \n",
        "    \n",
        "    # Concatenate all data into one DataFrame\n",
        "    df = pd.concat(dfs, ignore_index=True)\n",
        "    #df.head()\n",
        "\n",
        "    df = df.select_dtypes(exclude=['object','bool'])         #remove nan\n",
        "    df = df.loc[:, (df != 0).any(axis=0)]                    #remove zeros\n",
        "    df = df.drop(df.std()[(df.std() == 0)].index, axis=1)   #remove equals\n",
        "\n",
        "    sf = df[['roll', 'pitch', 'heading', 'rollRate', 'pitchRate', 'yawRate',\n",
        "       'groundSpeed',  'altitudeRelative', \n",
        "       'throttlePct', 'estimatorStatus.horizPosRatio',\n",
        "       'estimatorStatus.vertPosRatio',\n",
        "       'estimatorStatus.horizPosAccuracy','gps.courseOverGround']]\n",
        "    scaled_data = scale(sf)\n",
        "    \n",
        "\n",
        "    pca = PCA(n_components = 9)\n",
        "    pca.fit(scaled_data)\n",
        "    pca_data = pca.transform(scaled_data)\n",
        "\n",
        "    pca_data = pd.DataFrame(pca_data)\n",
        "\n",
        "    df_sf = pd.concat([pca_data, df[['attack']]], axis=1)\n",
        "\n",
        "    sf_t =df_sf\n",
        "\n",
        "    data_dim = sf_t.shape[1] -1\n",
        "    timesteps = 60\n",
        "    num_classes = 2\n",
        "\n",
        "\n",
        "    X = sf_t.drop(['attack'], axis =1).values\n",
        "    Y = sf_t[['attack']].values\n",
        "\n",
        "\n",
        "    ll = sf_t.shape[0] // timesteps\n",
        "    ll\n",
        "\n",
        "    x = np.array(X[0: (timesteps*ll)])\n",
        "    y = np.array(Y[0: (timesteps*ll)])\n",
        "    x.shape\n",
        "\n",
        "    X_t = np.reshape(x,(-1,timesteps,data_dim))\n",
        "    Y_t = np.reshape(y,(-1,timesteps,1))\n",
        "\n",
        "\n",
        "    Y_t = ReshapeY(Y_t,timesteps )\n",
        "    print(X_t.shape)\n",
        "    print(Y_t.shape)\n",
        "\n",
        "    # lb_make = LabelEncoder()\n",
        "    # Y_t = lb_make.fit_transform(Y_t)\n",
        "    # Y_t = tf.keras.utils.to_categorical(Y_t)\n",
        "    # X_t = X_t.astype(\"float32\")\n",
        "    # Y_t = Y_t.astype(\"float32\")\n",
        "    # X_t /= 255\n",
        "    \n",
        "    return (X_t,Y_t)\n",
        "\n",
        "\n",
        "def put_together(combined_array, asd):\n",
        "    combined_array = np.concatenate((combined_array, asd), axis=0)\n",
        "    #combined_array = np.delete(combined_array, 0, axis=0)\n",
        "    return combined_array\n",
        "\n",
        "\n",
        "def Delete_first(combined_array):\n",
        "    combined_array = np.delete(combined_array, 0, axis=0)\n",
        "    return combined_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq1jJsoLz1-w"
      },
      "source": [
        "import os\n",
        " \n",
        "paths = []    \n",
        "# rootdir = r'C:\\Users\\lenovo\\OneDrive - aggies.ncat.edu\\Desktop\\new correct files\\HEX New folder'\n",
        "for file in os.listdir(data_dir):\n",
        "    d = os.path.join(data_dir, file)\n",
        "    if os.path.isdir(d):\n",
        "        paths.append(d)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RldO0ugO0WbZ",
        "outputId": "de647ffe-5014-414e-fa8d-721f09976eba"
      },
      "source": [
        "paths"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/Colab Notebooks/HEX New folder/ST NPLANE New folder',\n",
              " '/content/drive/My Drive/Colab Notebooks/HEX New folder/QUAD New folder',\n",
              " '/content/drive/My Drive/Colab Notebooks/HEX New folder/TAIL VTOL New folder',\n",
              " '/content/drive/My Drive/Colab Notebooks/HEX New folder/h480']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_iMN_KM0Txj",
        "outputId": "ad528aa5-ab0b-4a2b-f9a4-b466f045bb10"
      },
      "source": [
        "from sklearn.preprocessing import scale\n",
        "\n",
        "i = 0\n",
        "for path in paths:\n",
        "    (Xa,Ya) = LOAD_data(path)\n",
        "    if  (i == 0):\n",
        "        X_ = Xa  \n",
        "        Y_ = Ya\n",
        "        i = i + 1 \n",
        "    else:\n",
        "        X_ = np.concatenate((X_, Xa), axis=0)\n",
        "        Y_ = np.concatenate((Y_, Ya), axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(461, 60, 9)\n",
            "(461,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n",
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2325, 60, 9)\n",
            "(2325,)\n",
            "(455, 60, 9)\n",
            "(455,)\n",
            "(603, 60, 9)\n",
            "(603,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJW3rAuU4ecR",
        "outputId": "c5491a2e-11b4-4564-9cb3-ff9b2e9f4c64"
      },
      "source": [
        "print(X_.shape)\n",
        "print(Y_.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3844, 60, 9)\n",
            "(3844,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6hW3b0b0BMz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORm_I1nuwJgk"
      },
      "source": [
        "X_train_D,X_test_D, Y_train_D, Y_test_D = train_test_split(X_, Y_, test_size=0.10, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4la6Vixrxejc",
        "outputId": "b60cd0ee-d1eb-4dcf-f2dc-f02814e0eba6"
      },
      "source": [
        "print(Y_test_D.shape, ':y test')\n",
        "print(Y_train_D.shape, ':y train')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(846,) :y test\n",
            "(2998,) :y train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGe4TbQIqEOX"
      },
      "source": [
        "def ReshapeY(Y_train,n):\n",
        "    Y = list()\n",
        "    for x in Y_train:\n",
        "        Y.append(find_1(x, n))\n",
        "\n",
        "    Y = np.array(Y)\n",
        "    return Y\n",
        "    print(Y.shape)\n",
        "    \n",
        "    \n",
        "# look for 1 ( spoof) in each   \n",
        "def find_1(x, n):\n",
        "    if 1 in x:\n",
        "        res = 1\n",
        "    else: \n",
        "        res = 0\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsZj6sP5pnKN"
      },
      "source": [
        "# normalize inputs from 0-255 to 0-1\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "#from keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# one-hot encode the labels\n",
        "num_classes = 2\n",
        "Y_train_D_hot = tf.keras.utils.to_categorical(Y_train_D-1, num_classes)\n",
        "Y_test_D_hot = tf.keras.utils.to_categorical(Y_test_D-1, num_classes)\n",
        "\n",
        "# # break training set into training and validation sets\n",
        "# (X_train, X_valid) = X_train_D[300:], X_train_D[:300]\n",
        "# (Y_train, Y_valid) = Y_train_D_hot[300:], Y_train_D_hot[:300]\n",
        "X_train,X_valid, Y_train, Y_valid = train_test_split(X_train_D, Y_train_D_hot, test_size=0.1, random_state=1)\n",
        "\n",
        "# X_train = X_train_D\n",
        "# Y_train = Y_train_D_hot\n",
        "X_test = X_test_D\n",
        "Y_test = Y_test_D_hot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8PMypQqr0Ir",
        "outputId": "c505ded9-502a-4f8b-ad21-669c145f88be"
      },
      "source": [
        "Y_valid.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(346, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVDDZrIyPaXd"
      },
      "source": [
        "# X_train = np.transpose(X_train, (1, 0, 2))\n",
        "# X_test = np.transpose(X_test, (1, 0, 2))\n",
        "# X_valid = np.transpose(X_valid, (1, 0, 2))\n",
        "\n",
        "# Y_train = np.transpose(Y_train, (1, 0, 2))\n",
        "# Y_test = np.transpose(Y_test, (1, 0, 2))\n",
        "# Y_valid = np.transpose(Y_valid, (1, 0, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBO1CipiRrUp",
        "outputId": "8af9c11b-08ce-40f0-bb38-c84b47ef2e55"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3113, 60, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSg6Fzjor0Dg",
        "outputId": "99082f85-a463-40cc-9c37-9c45ef135759"
      },
      "source": [
        "CNNch = 9\n",
        "\n",
        "# epch\n",
        "ne = 100\n",
        "\n",
        "modelC2 = Sequential()\n",
        "#1\n",
        "modelC2.add(Conv1D(filters=16, kernel_size=64,strides = 16, padding='same', activation='relu', \n",
        "                        input_shape=(60, CNNch)))\n",
        "modelC2.add(MaxPooling1D(pool_size=1))\n",
        "#2\n",
        "modelC2.add(Conv1D(filters=16, kernel_size=3, strides = 1, padding='same', activation='relu'))\n",
        "modelC2.add(MaxPooling1D(pool_size=1))\n",
        "#3\n",
        "modelC2.add(Conv1D(filters=32, kernel_size=3, strides = 1, padding='same', activation='relu'))\n",
        "modelC2.add(MaxPooling1D(pool_size=1))\n",
        "modelC2.add(Dropout(0.2))\n",
        "#4\n",
        "modelC2.add(Conv1D(filters=32, kernel_size=3, strides = 1, padding='same', activation='relu'))\n",
        "modelC2.add(MaxPooling1D(pool_size=1))\n",
        "modelC2.add(Dropout(0.2))\n",
        "#5\n",
        "modelC2.add(Conv1D(filters=32, kernel_size=3, strides = 1, padding='same', activation='relu'))\n",
        "#paper no padding?, Yes, to make 5th layer output 6 width and 3 after pooling\n",
        "#-> same seems to perform little better because of more parameter? \n",
        "# little diffrernt from the paper but keep it as padding = 'same'\n",
        "modelC2.add(MaxPooling1D(pool_size=1))  \n",
        "\n",
        "modelC2.add(Flatten())\n",
        "modelC2.add(Dense(10, activation='relu'))\n",
        "modelC2.add(Dropout(0.2))\n",
        "modelC2.add(Dense(2, activation='softmax'))\n",
        "\n",
        "modelC2.summary()\n",
        "\n",
        "\n",
        "# compile the model\n",
        "modelC2.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "checkpointer = ModelCheckpoint(filepath='CNNC2.weights.best.hdf5', verbose=1, \n",
        "                               save_best_only=True)\n",
        "\n",
        "hist = modelC2.fit(X_train[:,:,0:CNNch], Y_train, batch_size=32, epochs=ne,\n",
        "          validation_data=(X_valid[:,:,0:CNNch], Y_valid), callbacks=[checkpointer], \n",
        "          verbose=1, shuffle=True)\n",
        "\n",
        "# load the weights that yielded the best validation accuracy\n",
        "modelC2.load_weights('CNNC2.weights.best.hdf5')\n",
        "\n",
        "# evaluate and print test accuracy\n",
        "score = modelC2.evaluate(X_test[:,:,0:CNNch], Y_test, verbose=0)\n",
        "print('\\n', 'CNN Test accuracy:', score[1])\n",
        "\n",
        "score = modelC2.evaluate(X_train[:,:,0:CNNch], Y_train, verbose=0)\n",
        "print('\\n', 'CNN train accuracy:', score[1])\n",
        "\n",
        "score = modelC2.evaluate(X_valid[:,:,0:CNNch], Y_valid, verbose=0)\n",
        "print('\\n', 'CNN validation accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 4, 16)             9232      \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 4, 16)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 4, 16)             784       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 4, 16)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 4, 32)             1568      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 4, 32)             0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4, 32)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 4, 32)             3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 4, 32)             0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4, 32)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 4, 32)             3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 4, 32)             0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 22        \n",
            "=================================================================\n",
            "Total params: 19,104\n",
            "Trainable params: 19,104\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "98/98 [==============================] - 3s 9ms/step - loss: 0.2846 - accuracy: 0.8783 - val_loss: 0.1601 - val_accuracy: 0.9393\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.16008, saving model to CNNC2.weights.best.hdf5\n",
            "Epoch 2/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.1460 - accuracy: 0.9512 - val_loss: 0.1124 - val_accuracy: 0.9480\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.16008 to 0.11238, saving model to CNNC2.weights.best.hdf5\n",
            "Epoch 3/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0914 - accuracy: 0.9711 - val_loss: 0.1054 - val_accuracy: 0.9595\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.11238 to 0.10539, saving model to CNNC2.weights.best.hdf5\n",
            "Epoch 4/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0821 - accuracy: 0.9759 - val_loss: 0.0914 - val_accuracy: 0.9595\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.10539 to 0.09140, saving model to CNNC2.weights.best.hdf5\n",
            "Epoch 5/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0660 - accuracy: 0.9823 - val_loss: 0.5475 - val_accuracy: 0.8786\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.09140\n",
            "Epoch 6/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0509 - accuracy: 0.9865 - val_loss: 0.0712 - val_accuracy: 0.9798\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.09140 to 0.07124, saving model to CNNC2.weights.best.hdf5\n",
            "Epoch 7/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0395 - accuracy: 0.9913 - val_loss: 0.1874 - val_accuracy: 0.9624\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.07124\n",
            "Epoch 8/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0254 - accuracy: 0.9929 - val_loss: 0.0771 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.07124\n",
            "Epoch 9/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0263 - accuracy: 0.9936 - val_loss: 0.0597 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.07124 to 0.05966, saving model to CNNC2.weights.best.hdf5\n",
            "Epoch 10/100\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.0959 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.05966\n",
            "Epoch 11/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0173 - accuracy: 0.9961 - val_loss: 0.0963 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.05966\n",
            "Epoch 12/100\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0252 - accuracy: 0.9952 - val_loss: 0.1010 - val_accuracy: 0.9798\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.05966\n",
            "Epoch 13/100\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 0.9978 - val_loss: 0.1993 - val_accuracy: 0.9711\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.05966\n",
            "Epoch 14/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0160 - accuracy: 0.9958 - val_loss: 0.0435 - val_accuracy: 0.9884\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.05966 to 0.04353, saving model to CNNC2.weights.best.hdf5\n",
            "Epoch 15/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0155 - accuracy: 0.9971 - val_loss: 0.0639 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.04353\n",
            "Epoch 16/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0053 - accuracy: 0.9978 - val_loss: 0.1574 - val_accuracy: 0.9740\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.04353\n",
            "Epoch 17/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0123 - accuracy: 0.9965 - val_loss: 0.1515 - val_accuracy: 0.9798\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.04353\n",
            "Epoch 18/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.1476 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.04353\n",
            "Epoch 19/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.1786 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.04353\n",
            "Epoch 20/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0160 - accuracy: 0.9974 - val_loss: 0.1183 - val_accuracy: 0.9798\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.04353\n",
            "Epoch 21/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.0512 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.04353\n",
            "Epoch 22/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.0395 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.04353 to 0.03949, saving model to CNNC2.weights.best.hdf5\n",
            "Epoch 23/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.1780 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.03949\n",
            "Epoch 24/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.0919 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.03949\n",
            "Epoch 25/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.0388 - val_accuracy: 0.9913\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.03949 to 0.03879, saving model to CNNC2.weights.best.hdf5\n",
            "Epoch 26/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0984 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.03879\n",
            "Epoch 27/100\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0168 - accuracy: 0.9974 - val_loss: 0.0748 - val_accuracy: 0.9798\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.03879\n",
            "Epoch 28/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0859 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.03879\n",
            "Epoch 29/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0022 - accuracy: 0.9990 - val_loss: 0.1540 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.03879\n",
            "Epoch 30/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.1628 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.03879\n",
            "Epoch 31/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.1246 - val_accuracy: 0.9913\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.03879\n",
            "Epoch 32/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0079 - accuracy: 0.9987 - val_loss: 0.1672 - val_accuracy: 0.9884\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.03879\n",
            "Epoch 33/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 7.5229e-04 - accuracy: 0.9997 - val_loss: 0.2331 - val_accuracy: 0.9884\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.03879\n",
            "Epoch 34/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0167 - accuracy: 0.9984 - val_loss: 0.2368 - val_accuracy: 0.9798\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.03879\n",
            "Epoch 35/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0187 - accuracy: 0.9984 - val_loss: 0.0069 - val_accuracy: 0.9971\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.03879 to 0.00693, saving model to CNNC2.weights.best.hdf5\n",
            "Epoch 36/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.1149 - val_accuracy: 0.9913\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.00693\n",
            "Epoch 37/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 4.3666e-04 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.00693\n",
            "Epoch 38/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 3.5119e-04 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00693\n",
            "Epoch 39/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0135 - accuracy: 0.9974 - val_loss: 0.1574 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00693\n",
            "Epoch 40/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0139 - accuracy: 0.9987 - val_loss: 0.1451 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00693\n",
            "Epoch 41/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.1275 - val_accuracy: 0.9884\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00693\n",
            "Epoch 42/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.9990 - val_loss: 0.1012 - val_accuracy: 0.9942\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00693\n",
            "Epoch 43/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 1.5674e-04 - accuracy: 1.0000 - val_loss: 0.2837 - val_accuracy: 0.9798\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.00693\n",
            "Epoch 44/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0075 - accuracy: 0.9994 - val_loss: 0.0646 - val_accuracy: 0.9913\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00693\n",
            "Epoch 45/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0100 - accuracy: 0.9990 - val_loss: 0.0751 - val_accuracy: 0.9884\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00693\n",
            "Epoch 46/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0112 - accuracy: 0.9984 - val_loss: 0.0905 - val_accuracy: 0.9913\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00693\n",
            "Epoch 47/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0115 - accuracy: 0.9990 - val_loss: 0.0748 - val_accuracy: 0.9884\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00693\n",
            "Epoch 48/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.0652 - val_accuracy: 0.9884\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00693\n",
            "Epoch 49/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0930 - val_accuracy: 0.9942\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00693\n",
            "Epoch 50/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 4.7228e-04 - accuracy: 0.9997 - val_loss: 0.0784 - val_accuracy: 0.9942\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00693\n",
            "Epoch 51/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0996 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.00693\n",
            "Epoch 52/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2.9132e-04 - accuracy: 1.0000 - val_loss: 0.1132 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.00693\n",
            "Epoch 53/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.9984 - val_loss: 0.1485 - val_accuracy: 0.9884\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.00693\n",
            "Epoch 54/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0112 - accuracy: 0.9994 - val_loss: 0.2137 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.00693\n",
            "Epoch 55/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2.9079e-04 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.00693\n",
            "Epoch 56/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 4.2153e-04 - accuracy: 1.0000 - val_loss: 0.2879 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.00693\n",
            "Epoch 57/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0109 - accuracy: 0.9990 - val_loss: 0.6503 - val_accuracy: 0.9798\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.00693\n",
            "Epoch 58/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0102 - accuracy: 0.9997 - val_loss: 0.1401 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.00693\n",
            "Epoch 59/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0120 - accuracy: 0.9987 - val_loss: 0.1816 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.00693\n",
            "Epoch 60/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.1307 - val_accuracy: 0.9884\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.00693\n",
            "Epoch 61/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0087 - accuracy: 0.9990 - val_loss: 0.1566 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.00693\n",
            "Epoch 62/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.1789 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.00693\n",
            "Epoch 63/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.1510 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.00693\n",
            "Epoch 64/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 7.0828e-07 - accuracy: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.9884\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.00693\n",
            "Epoch 65/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0138 - accuracy: 0.9990 - val_loss: 0.2358 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.00693\n",
            "Epoch 66/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2.4290e-05 - accuracy: 1.0000 - val_loss: 0.1195 - val_accuracy: 0.9913\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.00693\n",
            "Epoch 67/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0045 - accuracy: 0.9997 - val_loss: 0.1002 - val_accuracy: 0.9942\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.00693\n",
            "Epoch 68/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2.6962e-04 - accuracy: 1.0000 - val_loss: 0.1583 - val_accuracy: 0.9884\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.00693\n",
            "Epoch 69/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0204 - accuracy: 0.9984 - val_loss: 0.2266 - val_accuracy: 0.9913\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.00693\n",
            "Epoch 70/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.1345 - val_accuracy: 0.9884\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.00693\n",
            "Epoch 71/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0100 - accuracy: 0.9990 - val_loss: 0.0999 - val_accuracy: 0.9971\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.00693\n",
            "Epoch 72/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.2597 - val_accuracy: 0.9884\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.00693\n",
            "Epoch 73/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0099 - accuracy: 0.9994 - val_loss: 0.1378 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.00693\n",
            "Epoch 74/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 1.3124e-04 - accuracy: 1.0000 - val_loss: 0.1562 - val_accuracy: 0.9884\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.00693\n",
            "Epoch 75/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0082 - accuracy: 0.9984 - val_loss: 0.2785 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.00693\n",
            "Epoch 76/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0186 - accuracy: 0.9987 - val_loss: 0.1083 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.00693\n",
            "Epoch 77/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 6.4857e-04 - accuracy: 0.9997 - val_loss: 0.2251 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.00693\n",
            "Epoch 78/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 3.0524e-04 - accuracy: 1.0000 - val_loss: 0.3390 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.00693\n",
            "Epoch 79/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0118 - accuracy: 0.9994 - val_loss: 0.1279 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.00693\n",
            "Epoch 80/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.1700 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.00693\n",
            "Epoch 81/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 1.5513e-04 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.00693\n",
            "Epoch 82/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2.6836e-04 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9884\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.00693\n",
            "Epoch 83/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0045 - accuracy: 0.9997 - val_loss: 0.2973 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.00693\n",
            "Epoch 84/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2.2197e-04 - accuracy: 1.0000 - val_loss: 0.3138 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.00693\n",
            "Epoch 85/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0087 - accuracy: 0.9994 - val_loss: 0.2683 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.00693\n",
            "Epoch 86/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2.4201e-04 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9884\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.00693\n",
            "Epoch 87/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 1.2477e-04 - accuracy: 1.0000 - val_loss: 0.4919 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.00693\n",
            "Epoch 88/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 3.4738e-04 - accuracy: 1.0000 - val_loss: 0.3780 - val_accuracy: 0.9798\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.00693\n",
            "Epoch 89/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0051 - accuracy: 0.9997 - val_loss: 0.2717 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.00693\n",
            "Epoch 90/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 1.5618e-04 - accuracy: 1.0000 - val_loss: 0.5780 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.00693\n",
            "Epoch 91/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 1.1799e-04 - accuracy: 1.0000 - val_loss: 0.5782 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.00693\n",
            "Epoch 92/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0127 - accuracy: 0.9994 - val_loss: 0.2860 - val_accuracy: 0.9798\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.00693\n",
            "Epoch 93/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0121 - accuracy: 0.9994 - val_loss: 0.4925 - val_accuracy: 0.9740\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.00693\n",
            "Epoch 94/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2.7581e-04 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9798\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.00693\n",
            "Epoch 95/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0129 - accuracy: 0.9997 - val_loss: 0.5063 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.00693\n",
            "Epoch 96/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 7.2939e-04 - accuracy: 0.9997 - val_loss: 0.4879 - val_accuracy: 0.9798\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.00693\n",
            "Epoch 97/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 3.1890e-04 - accuracy: 1.0000 - val_loss: 0.3678 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.00693\n",
            "Epoch 98/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.2332 - val_accuracy: 0.9884\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.00693\n",
            "Epoch 99/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2.2361e-04 - accuracy: 1.0000 - val_loss: 0.1588 - val_accuracy: 0.9884\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.00693\n",
            "Epoch 100/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 1.1083e-04 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9884\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.00693\n",
            "\n",
            " CNN Test accuracy: 0.9896103739738464\n",
            "\n",
            " CNN train accuracy: 1.0\n",
            "\n",
            " CNN validation accuracy: 0.9971098303794861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Dn_RcsndOL_h",
        "outputId": "6c55dfac-2dfd-42b7-e6b3-ddd01f77248c"
      },
      "source": [
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "#history = model.fit(train_x, train_y,validation_split = 0.1, epochs=50, batch_size=4)\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training accuracy', 'Validation accuracy'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7ZNjBmY30u0"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSlEGlct30mx"
      },
      "source": [
        " y_pred = modelC2.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W7XdvqO30i2",
        "outputId": "88cc5a67-c5bc-488c-82b6-33c77734b193"
      },
      "source": [
        " y_pred.round()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "CVYaTKtT30Y0",
        "outputId": "6e02b77d-1521-406e-b5b3-8313616fba40"
      },
      "source": [
        "ypreddf = pd.DataFrame(y_pred.round())\n",
        "ytestdf = pd.DataFrame(Y_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools\n",
        "\n",
        "print (classification_report(Y_test, y_pred.round()))\n",
        "\n",
        "\n",
        "cm = confusion_matrix(ytestdf[0], ypreddf[0])\n",
        "cm_plot_labels = ['Normal','Spoofed']\n",
        "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98       603\n",
            "           1       0.95      0.95      0.95       243\n",
            "\n",
            "   micro avg       0.97      0.97      0.97       846\n",
            "   macro avg       0.97      0.97      0.97       846\n",
            "weighted avg       0.97      0.97      0.97       846\n",
            " samples avg       0.97      0.97      0.97       846\n",
            "\n",
            "Confusion matrix, without normalization\n",
            "[[231  12]\n",
            " [ 11 592]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQBiM2mO4sMI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d36967a-6d38-4a35-e7bd-0cff2944af81"
      },
      "source": [
        "from sklearn.metrics import jaccard_score, f1_score, accuracy_score,recall_score, precision_score\n",
        "\n",
        "print(\"Avg F1-score: %.4f\" % f1_score(Y_test, y_pred.round(), average='weighted'))\n",
        "print(\"Jaccard score: %.4f\" % jaccard_score(Y_test, y_pred.round(), average='weighted'))\n",
        "print(\"Recall score: %.4f\" % recall_score(Y_test, y_pred.round(), average='weighted'))\n",
        "print(\"Precision score: %.4f\" % precision_score(Y_test, y_pred.round(), average='weighted'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg F1-score: 0.9728\n",
            "Jaccard score: 0.9473\n",
            "Recall score: 0.9728\n",
            "Precision score: 0.9728\n"
          ]
        }
      ]
    }
  ]
}